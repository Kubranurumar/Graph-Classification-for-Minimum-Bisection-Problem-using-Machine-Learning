{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install node2vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "_RlIPhNoeCij",
        "outputId": "00e27f97-bc78-4638-c6a7-8b304c51707f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting node2vec\n",
            "  Downloading node2vec-0.4.6-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: gensim<5.0.0,>=4.1.2 in /usr/local/lib/python3.10/dist-packages (from node2vec) (4.3.2)\n",
            "Requirement already satisfied: joblib<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from node2vec) (1.3.2)\n",
            "Collecting networkx<3.0,>=2.5 (from node2vec)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from node2vec) (1.23.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.55.1 in /usr/local/lib/python3.10/dist-packages (from node2vec) (4.66.1)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.1.2->node2vec) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.1.2->node2vec) (6.4.0)\n",
            "Installing collected packages: networkx, node2vec\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.2.1\n",
            "    Uninstalling networkx-3.2.1:\n",
            "      Successfully uninstalled networkx-3.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed networkx-2.8.8 node2vec-0.4.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "networkx"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import random\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from joblib import load\n",
        "import pickle\n",
        "from node2vec import Node2Vec\n",
        "from gensim.models import Word2Vec\n",
        "from networkx.algorithms import community"
      ],
      "metadata": {
        "id": "h6H0O6r9apQa"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_Big_Graphs():\n",
        "  num_nodes = 2000\n",
        "  BigList_2000 =[]\n",
        "  random_complete = nx.complete_graph(2000)\n",
        "  for i in range(2000):\n",
        "    for j in range(i + 1, 2000):\n",
        "      if random.random() < 0.5:\n",
        "        random_complete.remove_edge(i, j)\n",
        "  BigList_2000.append(random_complete)\n",
        "  #-------------------------------------------------\n",
        "  random_multigraph = nx.MultiGraph()\n",
        "  for i in range(num_nodes):\n",
        "      random_multigraph.add_node(i)\n",
        "  for i in range(num_nodes):\n",
        "      for j in range(i + 1, num_nodes):\n",
        "          if random.random() < 0.5:\n",
        "              random_multigraph.add_edge(i, j)\n",
        "  BigList_2000.append(random_multigraph)\n",
        "  #-------------------------------------------------\n",
        "  pseudograph = nx.MultiGraph()\n",
        "  pseudograph.add_nodes_from(range(num_nodes))\n",
        "  for node in pseudograph.nodes():\n",
        "      pseudograph.add_edge(node, node)\n",
        "      random_nodes = random.sample(pseudograph.nodes(), k=3)\n",
        "      pseudograph.add_edges_from([(node, random_node) for random_node in random_nodes])\n",
        "  BigList_2000.append(pseudograph)\n",
        "  #-------------------------------------------------\n",
        "  planar_graph = nx.random_geometric_graph(num_nodes, radius=0.2)\n",
        "  while not nx.is_connected(planar_graph):\n",
        "      planar_graph = nx.random_geometric_graph(num_nodes, radius=0.2)\n",
        "  BigList_2000.append(planar_graph)\n",
        "  #-------------------------------------------------\n",
        "  def random_hamiltonian_graph(n):\n",
        "      graph = nx.random_regular_graph(2, n)\n",
        "      for i in range(n):\n",
        "          for j in range(i + 1, n):\n",
        "              if random.random() < 0.5 and not graph.has_edge(i, j):\n",
        "                  graph.add_edge(i, j)\n",
        "      return graph\n",
        "  random_hamiltonian_graph = random_hamiltonian_graph(num_nodes)\n",
        "  BigList_2000.append(random_hamiltonian_graph)\n",
        "  return BigList_2000"
      ],
      "metadata": {
        "id": "oN0_zKPhar4Q"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_main_graphs(num_nodes):\n",
        "  main_list =[]\n",
        "  random_regular_3 = nx.random_regular_graph(3, num_nodes)\n",
        "  random_regular_20 = nx.random_regular_graph(20, num_nodes)\n",
        "  main_list.append(random_regular_3)\n",
        "  main_list.append(random_regular_20)\n",
        "  #-------------------------------------------------\n",
        "  # Create a random connected graph by generating a random spanning tree\n",
        "  random_connected_tree = nx.random_tree(num_nodes)\n",
        "  # Add additional edges to maintain connectivity\n",
        "  while not nx.is_connected(random_connected_tree):\n",
        "      node1 = random.choice(list(random_connected_tree.nodes()))\n",
        "      node2 = random.choice(list(random_connected_tree.nodes()))\n",
        "      if node1 != node2 and not random_connected_tree.has_edge(node1, node2):\n",
        "          random_connected_tree.add_edge(node1, node2)\n",
        "  main_list.append(random_connected_tree)\n",
        "  #-------------------------------------------------\n",
        "  def generate_random_connected_cycle_graph(num_nodes):\n",
        "      if num_nodes < 3:\n",
        "          raise ValueError(\"Number of nodes must be at least 3 for a cycle.\")\n",
        "      cycle_graph = nx.cycle_graph(num_nodes)\n",
        "      # Connect the cycle to form a connected cycle graph\n",
        "      connected_cycle_graph = nx.connected_watts_strogatz_graph(num_nodes, 2, 0.1)\n",
        "      return connected_cycle_graph\n",
        "  random_cycle_graph = generate_random_connected_cycle_graph(num_nodes)\n",
        "  main_list.append(random_cycle_graph)\n",
        "  #-------------------------------------------------\n",
        "  def generate_random_connected_barabasi_albert_graph(num_nodes, m):\n",
        "      if num_nodes <= m:\n",
        "          raise ValueError(\"Number of nodes must be greater than m for a Barabási-Albert graph.\")\n",
        "      ba_graph = nx.barabasi_albert_graph(num_nodes, m)\n",
        "      while not nx.is_connected(ba_graph):\n",
        "          # Add edges to connect the graph\n",
        "          non_edges = list(nx.non_edges(ba_graph))\n",
        "          edge_to_add = non_edges[0]\n",
        "          ba_graph.add_edge(*edge_to_add)\n",
        "      return ba_graph\n",
        "  m_parameter = 2\n",
        "  random_connected_ba_graph = generate_random_connected_barabasi_albert_graph(num_nodes, m_parameter)\n",
        "  main_list.append(random_connected_ba_graph)\n",
        "  #-------------------------------------------------\n",
        "  def generate_random_connected_erdos_renyi_graph(num_nodes, probability):\n",
        "      er_graph = nx.erdos_renyi_graph(num_nodes, probability)\n",
        "      while not nx.is_connected(er_graph):\n",
        "          # Add edges to connect the graph\n",
        "          non_edges = list(nx.non_edges(er_graph))\n",
        "          edge_to_add = non_edges[0]\n",
        "          er_graph.add_edge(*edge_to_add)\n",
        "      return er_graph\n",
        "  edge_probability = 0.1  # Adjust as needed\n",
        "  random_connected_er_graph = generate_random_connected_erdos_renyi_graph(num_nodes, edge_probability)\n",
        "  main_list.append(random_connected_er_graph)\n",
        "  #-------------------------------------------------\n",
        "  k = 2  # Each node is connected to k nearest neighbors\n",
        "  p = 0.3  # Probability of rewiring each edge\n",
        "  random_graph_ws = nx.watts_strogatz_graph(num_nodes, k, p)\n",
        "  main_list.append(random_graph_ws)\n",
        "  #-------------------------------------------------\n",
        "  k = 10  # Each node is connected to k nearest neighbors\n",
        "  p = 0.3  # Probability of rewiring each edge\n",
        "  random_graph_ws = nx.watts_strogatz_graph(num_nodes, k, p)\n",
        "  main_list.append(random_graph_ws)\n",
        "  #-------------------------------------------------\n",
        "\n",
        "  def generate_connected_random_geometric_graph(num_nodes, radius):\n",
        "      random_geo_graph = nx.random_geometric_graph(num_nodes, radius)\n",
        "      while not nx.is_connected(random_geo_graph):\n",
        "          # Connect the graph by adding edges\n",
        "          non_edges = list(nx.non_edges(random_geo_graph))\n",
        "          random_edge = random.choice(non_edges)\n",
        "          random_geo_graph.add_edge(*random_edge)\n",
        "      return random_geo_graph\n",
        "  radius = 0.1  # Adjust as needed\n",
        "  connected_random_geo_graph = generate_connected_random_geometric_graph(num_nodes, radius)\n",
        "  main_list.append(connected_random_geo_graph)\n",
        "  #-------------------------------------------------\n",
        "  def generate_connected_random_internet_graph(num_nodes, k, p):\n",
        "      internet_graph = nx.random_internet_as_graph(num_nodes)\n",
        "      while not nx.is_connected(internet_graph):\n",
        "          non_edges = list(nx.non_edges(internet_graph))\n",
        "          random_edge = non_edges[0]\n",
        "          internet_graph.add_edge(*random_edge)\n",
        "      undirected_internet_graph = internet_graph.to_undirected()\n",
        "      connected_random_internet_graph = nx.connected_watts_strogatz_graph(num_nodes, k, p)\n",
        "      return connected_random_internet_graph\n",
        "  k_parameter = 5\n",
        "  p_parameter = 0.5\n",
        "  connected_random_internet_graph = generate_connected_random_internet_graph(num_nodes, k_parameter, p_parameter)\n",
        "  main_list.append(connected_random_internet_graph)\n",
        "  #-------------------------------------------------\n",
        "  return main_list\n"
      ],
      "metadata": {
        "id": "dut1HwJcazIf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BigGraphs = create_Big_Graphs()\n",
        "main_list = create_main_graphs(5000)\n",
        "main_list2 = create_main_graphs(8000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88tHVQnBfOCW",
        "outputId": "98fbf129-1204-4de4-bd22-be99b2ced4c2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-70e2a112d68a>:24: DeprecationWarning: Sampling from a set deprecated\n",
            "since Python 3.9 and will be removed in a subsequent version.\n",
            "  random_nodes = random.sample(pseudograph.nodes(), k=3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Label Graph\n",
        "def labelling_kernighan(G):\n",
        "    Y =[]\n",
        "\n",
        "    #iteration number!!!!!!\n",
        "    #Dense graph\n",
        "    if((G.number_of_edges() >= math.comb(G.number_of_nodes(),2)/2) & (G.number_of_edges() <= math.comb(G.number_of_nodes(),2))):\n",
        "      iteration_number=G.number_of_nodes()\n",
        "    else:\n",
        "    #sparse graph\n",
        "      iteration_number=0.04*G.number_of_nodes()*math.log(G.number_of_nodes())\n",
        "\n",
        "    partitions = community.kernighan_lin.kernighan_lin_bisection(G, max_iter=int(iteration_number))\n",
        "    is_equal_partition = (len(list(partitions[0])) > (G.number_of_nodes()/2)-G.number_of_nodes()*0.01) & (len(list(partitions[0])) < (G.number_of_nodes()/2) + G.number_of_nodes() * 0.01) & (len(list(partitions[1])) > (G.number_of_nodes()/2) - G.number_of_nodes()*0.01) & (len(list(partitions[1])) < (G.number_of_nodes()/2) + G.number_of_nodes()*0.01)\n",
        "\n",
        "    graph_1 = G.subgraph(partitions[0])\n",
        "    graph_2 = G.subgraph(partitions[1])\n",
        "\n",
        "    is_connected_partition1 = nx.is_connected(graph_1)\n",
        "    is_connected_partition2 = nx.is_connected(graph_2)\n",
        "\n",
        "    if is_connected_partition1 and is_connected_partition2 and is_equal_partition:\n",
        "        result = True\n",
        "        Y.append(1)\n",
        "    else:\n",
        "        result = False\n",
        "        Y.append(0)\n",
        "\n",
        "    return Y\n",
        "\n",
        "#Feature extraction with Node2vec\n",
        "def run_n2v(G, dimensions=64, walk_length=80, num_walks=10, p=1, q=1, window=10):\n",
        "\n",
        "    mdl = Node2Vec(\n",
        "        G,\n",
        "        dimensions=dimensions,\n",
        "        walk_length=walk_length,\n",
        "        num_walks=num_walks,\n",
        "        p=p,\n",
        "        q=q\n",
        "    )\n",
        "    mdl = mdl.fit(window=window)\n",
        "\n",
        "    # Gömme vektörlerini alın\n",
        "    vectors = [mdl.wv.get_vector(str(x)) for x in G.nodes()]\n",
        "    return vectors\n",
        "\n",
        "#Feature extraction with DeepWalk\n",
        "#We will choose the walk number and walk length by trial and error\n",
        "def deepwalk(G,num_walks,walk_length):\n",
        "    # Generate walks for DeepWalk\n",
        "    walks = []\n",
        "\n",
        "    for _ in range(num_walks):\n",
        "        for node in G.nodes():\n",
        "            walk = [node]\n",
        "            for _ in range(walk_length - 1):\n",
        "                neighbors = list(G.neighbors(walk[-1]))\n",
        "                if neighbors:\n",
        "                    walk.append(neighbors[0])  # Rastgele bir komşuya ilerleyin\n",
        "                else:\n",
        "                    break\n",
        "            walks.append(walk)\n",
        "\n",
        "    # Word2Vec modelini eğitin\n",
        "    model = Word2Vec(walks, vector_size=64, window=5, min_count=0, sg=1, workers=4)\n",
        "\n",
        "    # Gömme vektörlerini alın\n",
        "    embedding_vectors = [model.wv.get_vector(node) for node in G.nodes()]\n",
        "\n",
        "    # Herhangi bir düğümün gömme vektörünü alın\n",
        "\n",
        "    return embedding_vectors\n",
        "\n",
        "#median of features of nodes\n",
        "def median_of_embeddings(G,vectors_array):\n",
        "    n = G.number_of_nodes()\n",
        "    final_embedded= []\n",
        "    temp_embedded = []\n",
        "    for j in range(vectors_array.shape[1]):\n",
        "        for i in range(vectors_array.shape[0]):  # Iterate over rows\n",
        "            element = vectors_array[i][j]\n",
        "            temp_embedded.append(element)\n",
        "        temp_embedded.sort()\n",
        "        median = np.median(temp_embedded)\n",
        "        final_embedded.append(median)\n",
        "    return final_embedded\n",
        "\n",
        "def preprocessing(G):\n",
        "\n",
        "    while not nx.is_connected(G):\n",
        "        node1 = random.choice(list(G.nodes()))\n",
        "        node2 = random.choice(list(G.nodes()))\n",
        "        if node1 != node2 and not G.has_edge(node1, node2):\n",
        "            G.add_edge(node1, node2)\n",
        "\n",
        "    #getting vectors\n",
        "\n",
        "    vectors_array_deepwalk = np.array(deepwalk(G,10,5))\n",
        "\n",
        "    embedded_vector = median_of_embeddings(G,vectors_array_deepwalk)\n",
        "\n",
        "    columns_to_drop_dw = [4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 21, 35, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]\n",
        "    extracted_vector = np.delete(embedded_vector, columns_to_drop_dw)\n",
        "\n",
        "    return extracted_vector\n"
      ],
      "metadata": {
        "id": "EmU17xoCULqy"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your model from .sav file\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/Team1_last_model.sav','rb') as file:\n",
        "  model_rf = load(file)\n"
      ],
      "metadata": {
        "id": "xBSdP2SIU3Ba"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input the graph to be predicted and choose graph representation type\n",
        "\n",
        "for item in BigGraphs:\n",
        "    data_BigGraphs = preprocessing(item)\n",
        "    data_BigGraphs = data_BigGraphs.reshape(1,-1)\n",
        "    label_data_BigGraphs = labelling_kernighan(item)\n",
        "    print(\"The BigGraphs label is: \", label_data_BigGraphs)\n",
        "\n",
        "\n",
        "    predict_Big_Graphs = model_rf.predict(data_BigGraphs)\n",
        "    print(\"The predict is \", predict_Big_Graphs)\n",
        "\n",
        "for item in main_list:\n",
        "    data_main_list = preprocessing(item)\n",
        "    data_main_list = data_main_list.reshape(1,-1)\n",
        "    label_data_main_list = labelling_kernighan(item)\n",
        "    print(\"The main_list label is: \", label_data_main_list)\n",
        "\n",
        "    predict_main_list = model_rf.predict(data_main_list)\n",
        "    print(\"The predict is \", predict_main_list)\n",
        "\n",
        "for item in main_list2:\n",
        "    data_main_list_2 = preprocessing(item)\n",
        "    data_main_list_2 = data_main_list_2.reshape(1,-1)\n",
        "    label_data_main_list_2 = labelling_kernighan(item)\n",
        "    print(\"The main_list_2 label is: \", label_data_main_list_2)\n",
        "\n",
        "    predict_main_list2 = model_rf.predict(data_main_list_2)\n",
        "    print(\"The predict is \", predict_main_list2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzmmkC_ofCnU",
        "outputId": "2035f81a-ad58-4fc5-dcfc-1fe8196453fe"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BigGraphs label is:  [1]\n",
            "The predict is  [0]\n",
            "The BigGraphs label is:  [1]\n",
            "The predict is  [1]\n",
            "The BigGraphs label is:  [1]\n",
            "The predict is  [1]\n",
            "The BigGraphs label is:  [1]\n",
            "The predict is  [1]\n",
            "The BigGraphs label is:  [1]\n",
            "The predict is  [1]\n",
            "The main_list label is:  [1]\n",
            "The predict is  [1]\n",
            "The main_list label is:  [1]\n",
            "The predict is  [1]\n",
            "The main_list label is:  [0]\n",
            "The predict is  [0]\n",
            "The main_list label is:  [0]\n",
            "The predict is  [1]\n",
            "The main_list label is:  [1]\n",
            "The predict is  [1]\n",
            "The main_list label is:  [1]\n",
            "The predict is  [1]\n",
            "The main_list label is:  [0]\n",
            "The predict is  [0]\n",
            "The main_list label is:  [1]\n",
            "The predict is  [0]\n",
            "The main_list label is:  [1]\n",
            "The predict is  [1]\n",
            "The main_list label is:  [1]\n",
            "The predict is  [0]\n",
            "The main_list_2 label is:  [1]\n",
            "The predict is  [0]\n",
            "The main_list_2 label is:  [1]\n",
            "The predict is  [0]\n",
            "The main_list_2 label is:  [0]\n",
            "The predict is  [0]\n",
            "The main_list_2 label is:  [0]\n",
            "The predict is  [0]\n",
            "The main_list_2 label is:  [1]\n",
            "The predict is  [1]\n",
            "The main_list_2 label is:  [1]\n",
            "The predict is  [1]\n",
            "The main_list_2 label is:  [0]\n",
            "The predict is  [0]\n",
            "The main_list_2 label is:  [1]\n",
            "The predict is  [1]\n",
            "The main_list_2 label is:  [1]\n",
            "The predict is  [1]\n",
            "The main_list_2 label is:  [1]\n",
            "The predict is  [0]\n"
          ]
        }
      ]
    }
  ]
}